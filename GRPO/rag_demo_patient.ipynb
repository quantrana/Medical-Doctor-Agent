{"cells":[{"cell_type":"markdown","metadata":{"id":"CnMQr3GH5TwT"},"source":["# Doctor RL - Chatbot Interface\n","## Based on SFT and GRPO trained Qwen3-1.7B"],"id":"CnMQr3GH5TwT"},{"cell_type":"markdown","id":"10d0fca9-cf17-4bca-a5cb-22ce7bbb0ec8","metadata":{"id":"10d0fca9-cf17-4bca-a5cb-22ce7bbb0ec8"},"source":["# Environment Setup"]},{"cell_type":"code","source":["try: import numpy, PIL; get_numpy = f'numpy=={numpy.__version__}'; get_pil = f'pillow=={PIL.__version__}'\n","except: get_numpy = 'numpy'; get_pil = 'pillow'\n","try: import subprocess; is_t4 = 'Tesla T4' in str(subprocess.check_output(['nvidia-smi']))\n","except: is_t4 = False\n","get_vllm, get_triton = ('vllm==0.9.2', 'triton==3.2.0') if is_t4 else ('vllm==0.10.2', 'triton')\n","!uv pip install -qqq --upgrade unsloth {get_vllm} {get_numpy} {get_pil} torchvision bitsandbytes xformers\n","!uv pip install -qqq {get_triton}\n","!uv pip install transformers==4.56.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dz_pVmZbtW7H","executionInfo":{"status":"ok","timestamp":1762132572399,"user_tz":-660,"elapsed":1761,"user":{"displayName":"Paul Butler","userId":"08166718738908281890"}},"outputId":"7d05122a-42f5-482c-c2b3-0cc770412214"},"id":"dz_pVmZbtW7H","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtransformers==4.56.2                                                          \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mfilelock==3.20.0                                                              \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhuggingface-hub==0.36.0                                                       \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mnumpy==2.0.2                                                                  \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpackaging==25.0                                                               \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpyyaml==6.0.3                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mregex==2025.10.23                                                             \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mrequests==2.32.5                                                              \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtokenizers==0.22.1                                                            \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2msafetensors==0.6.2                                                            \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtqdm==4.67.1                                                                  \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mfsspec==2025.9.0                                                              \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtyping-extensions==4.15.0                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhf-xet==1.2.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhf-xet==1.2.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mcharset-normalizer==3.4.4                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2midna==3.11                                                                    \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2murllib3==2.5.0                                                                \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m18 packages\u001b[0m \u001b[2min 12ms\u001b[0m\u001b[0m\n","\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 64ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 51ms\u001b[0m\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.56.2\u001b[0m\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","%cd /content/drive/MyDrive/RL/multi-reward-medical-reasoning\n","!ls\n","\n","#%cd /content/drive/MyDrive/Reinforcement_Learning/RL_Project/multi-reward-medical-reasoning\n","#!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IN_-e1-4hAjb","executionInfo":{"status":"ok","timestamp":1762132576313,"user_tz":-660,"elapsed":3911,"user":{"displayName":"Paul Butler","userId":"08166718738908281890"}},"outputId":"9ff6c964-349b-4825-fa71-74799e4e78c1"},"id":"IN_-e1-4hAjb","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/.shortcut-targets-by-id/1OhvtbvB42jF4ERuZvuDpJ8-HFw4kMXsD/multi-reward-medical-reasoning\n","backup.ipynb\t\t      qwen3-1.7b-base_sft\n","base.ipynb\t\t      qwen3-1.7b_grpo\n","grpo_trainer_lora_model       qwen3-1.7b_sft\n","huggingface_tokenizers_cache  rag_demo.ipynb\n","instruct.ipynb\t\t      unsloth_compiled_cache\n","ppo_baselines\t\t      unsloth_training_checkpoints\n","qwen3-1.7b-base_grpo\t      wandb\n"]}]},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","from vllm import SamplingParams\n","\n","import gc\n","import re\n","import time\n","import threading\n","import numpy as np\n","import pandas as pd\n","import gradio as gr\n","\n","import torch\n","import torch.nn.functional as F\n","from safetensors import safe_open\n","from datasets import load_dataset\n","from transformers import TextIteratorStreamer\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity"],"metadata":{"id":"carQKP_eeNuz"},"id":"carQKP_eeNuz","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Setup"],"metadata":{"id":"7oZ3YeqLe0OS"},"id":"7oZ3YeqLe0OS"},{"cell_type":"code","source":["model_id = 'unsloth/Qwen3-1.7B-Base'          # unsloth/Qwen3-1.7B\n","model_name = model_id.split('/')[-1].lower()  # Extract model name from ID\n","max_seq_length = 2048                         # Can increase for longer reasoning traces\n","lora_rank = 32                                # Larger rank = smarter, but slower\n","lora_path = f'./{model_name}_grpo'            # Path to saved GRPO LoRA"],"metadata":{"id":"XGBTFiJ2e1vS"},"id":"XGBTFiJ2e1vS","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(lora_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCrn3o_uksuU","executionInfo":{"status":"ok","timestamp":1762132576337,"user_tz":-660,"elapsed":4,"user":{"displayName":"Paul Butler","userId":"08166718738908281890"}},"outputId":"5ae35297-23dd-4e45-9573-862ab573815f"},"id":"NCrn3o_uksuU","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["./qwen3-1.7b-base_grpo\n"]}]},{"cell_type":"code","source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name=lora_path,       # Reload GRPO weights\n","    max_seq_length=max_seq_length,\n","    load_in_4bit=False,         # False for LoRA 16bit\n","    fast_inference=True,        # Enable vLLM fast inference\n","    max_lora_rank=lora_rank,\n","    gpu_memory_utilization=0.8, # Reduce if out of memory\n",")\n","lora_request = model.load_lora(lora_path)\n","FastLanguageModel.for_inference(model)\n","embed_model = SentenceTransformer('all-MiniLM-L6-v2')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":885,"referenced_widgets":["6b5bf91909d14565a0a86c58c6e8ba0f","74cfc90539d44500972378dfe2f45f9d","8f8a4a5d25eb44e6ab752aea0d345f1c","d99bef70a19a4f3596d88477189f42ee","daac6cd95fa44d1da290766aedc9ca0f","81ea6fe82804471a8f0480e5b49c0400","c1dab6533f3346d4aa13226ab8f4b641","7020cc112f3f4249987a628f3a6e33e1","6d72a6739b314d1e802457b903a9bc47","e29aee0fdbd042159df67fb9f470256e","fecedfb4578a47f3a6a8a859bff7e1f9"]},"id":"u-Ao9IY3e6A9","executionInfo":{"status":"ok","timestamp":1762132658156,"user_tz":-660,"elapsed":81813,"user":{"displayName":"Paul Butler","userId":"08166718738908281890"}},"outputId":"274450b0-9ba1-47b2-c13c-a2c67eccc9e1"},"id":"u-Ao9IY3e6A9","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO 11-03 01:16:16 [vllm_utils.py:694] Unsloth: Patching vLLM v1 graph capture\n","INFO 11-03 01:16:16 [vllm_utils.py:722] Unsloth: Patching vLLM v0 graph capture\n","==((====))==  Unsloth 2025.10.12: Fast Qwen3 patching. Transformers: 4.56.2. vLLM: 0.10.2.\n","   \\\\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.318 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.4.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post1. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","Unsloth: vLLM loading unsloth/Qwen3-1.7B-Base with actual GPU utilization = 13.83%\n","Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 79.32 GB.\n","Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 2048. Num Sequences = 192.\n","Unsloth: vLLM's KV Cache can use up to 7.7 GB. Also swap space = 6 GB.\n","WARNING 11-03 01:16:32 [compilation.py:456] full_cuda_graph is deprecated, use cudagraph_mode=FULL instead.\n","Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.\n","INFO 11-03 01:16:32 [utils.py:328] non-default args: {'dtype': torch.bfloat16, 'seed': 0, 'max_model_len': 2048, 'enable_prefix_caching': True, 'swap_space': 6, 'gpu_memory_utilization': 0.13826704495174866, 'max_num_batched_tokens': 2048, 'max_num_seqs': 192, 'max_logprobs': 0, 'disable_log_stats': True, 'enable_lora': True, 'max_lora_rank': 32, 'enable_chunked_prefill': True, 'compilation_config': {\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":null,\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":12,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":null,\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{},\"max_capture_size\":null,\"local_cache_dir\":null}, 'model': 'unsloth/Qwen3-1.7B-Base'}\n","INFO 11-03 01:16:33 [__init__.py:742] Resolved architecture: Qwen3ForCausalLM\n","INFO 11-03 01:16:33 [__init__.py:1815] Using max model len 2048\n","INFO 11-03 01:16:33 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.\n","WARNING 11-03 01:16:33 [lora.py:92] `lora_extra_vocab_size` is deprecated and will be removed in v0.12.0. Additional vocabulary support for LoRA adapters is being phased out.\n","INFO 11-03 01:16:35 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='unsloth/Qwen3-1.7B-Base', speculative_config=None, tokenizer='unsloth/Qwen3-1.7B-Base', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Qwen3-1.7B-Base, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":12,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{},\"max_capture_size\":384,\"local_cache_dir\":null}\n","INFO 11-03 01:16:36 [gpu_model_runner.py:2338] Starting to load model unsloth/Qwen3-1.7B-Base...\n","INFO 11-03 01:16:37 [gpu_model_runner.py:2370] Loading model from scratch...\n","INFO 11-03 01:16:37 [weight_utils.py:348] Using model weights format ['*.safetensors']\n","INFO 11-03 01:16:38 [weight_utils.py:406] No model.safetensors.index.json found in remote.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b5bf91909d14565a0a86c58c6e8ba0f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["INFO 11-03 01:16:39 [default_loader.py:268] Loading weights took 1.19 seconds\n","INFO 11-03 01:16:41 [gpu_model_runner.py:2392] Model loading took 3.2841 GiB and 1.968943 seconds\n","INFO 11-03 01:16:52 [backends.py:539] Using cache directory: /root/.cache/vllm/torch_compile_cache/1d9678ad38/rank_0_0/backbone for vLLM's torch.compile\n","INFO 11-03 01:16:52 [backends.py:550] Dynamo bytecode transform time: 9.57 s\n","INFO 11-03 01:16:57 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 4.169 s\n","INFO 11-03 01:16:59 [monitor.py:34] torch.compile takes 9.57 s in total\n","INFO 11-03 01:17:02 [gpu_worker.py:298] Available KV cache memory: 6.64 GiB\n","INFO 11-03 01:17:03 [kv_cache_utils.py:864] GPU KV cache size: 62,128 tokens\n","INFO 11-03 01:17:03 [kv_cache_utils.py:868] Maximum concurrency for 2,048 tokens per request: 30.34x\n","INFO 11-03 01:17:03 [vllm_utils.py:699] Unsloth: Running patched vLLM v1 `capture_model`.\n","INFO 11-03 01:17:03 [vllm_utils.py:699] Unsloth: Running patched vLLM v1 `capture_model`.\n","WARNING 11-03 01:17:03 [gpu_model_runner.py:3258] CUDAGraphMode.FULL is not supported with FlashAttentionMetadataBuilder backend (support: AttentionCGSupport.UNIFORM_BATCH); setting cudagraph_mode=FULL_AND_PIECEWISE\n"]},{"output_type":"stream","name":"stderr","text":["Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:07<00:00,  6.86it/s]\n","Capturing CUDA graphs (decode, FULL): 100%|██████████| 27/27 [00:03<00:00,  7.00it/s]"]},{"output_type":"stream","name":"stdout","text":["INFO 11-03 01:17:14 [gpu_model_runner.py:3118] Graph capturing finished in 11 secs, took 0.67 GiB\n","INFO 11-03 01:17:14 [vllm_utils.py:706] Unsloth: Patched vLLM v1 graph capture finished in 11 secs.\n","INFO 11-03 01:17:14 [vllm_utils.py:706] Unsloth: Patched vLLM v1 graph capture finished in 11 secs.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["INFO 11-03 01:17:16 [gpu_worker.py:391] Free memory on device (14.42/79.32 GiB) on startup. Desired GPU memory utilization is (0.13826704495174866, 10.97 GiB). Actual usage is 3.28 GiB for weight, 1.04 GiB for peak activation, 0.0 GiB for non-torch memory, and 0.67 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=6247239372` to fit into requested memory, or `--kv-cache-memory=9958752768` to fully utilize gpu memory. Current kv cache memory in use is 7125946060 bytes.\n","INFO 11-03 01:17:17 [core.py:218] init engine (profile, create kv cache, warmup model) took 35.43 seconds\n","INFO 11-03 01:17:18 [llm.py:295] Supported_tasks: ('generate',)\n","INFO 11-03 01:17:18 [__init__.py:36] No IOProcessor plugins requested by the model\n","Unsloth: Just some info: will skip parsing ['post_layernorm', 'q_norm', 'post_attention_layernorm', 'attention_norm', 'pre_feedforward_layernorm', 'layer_norm1', 'norm2', 'post_feedforward_layernorm', 'norm1', 'layer_norm2', 'k_norm', 'input_layernorm', 'ffn_norm']\n","Unsloth: Just some info: will skip parsing ['post_layernorm', 'q_norm', 'cross_attn_post_attention_layernorm', 'post_attention_layernorm', 'attention_norm', 'pre_feedforward_layernorm', 'layer_norm1', 'cross_attn_input_layernorm', 'norm2', 'post_feedforward_layernorm', 'norm1', 'layer_norm2', 'k_norm', 'input_layernorm', 'ffn_norm']\n"]}]},{"cell_type":"markdown","id":"b629c66c-dcec-4515-bb7a-e67deca86b90","metadata":{"id":"b629c66c-dcec-4515-bb7a-e67deca86b90"},"source":["# Prepare the knowledge base\n"]},{"cell_type":"code","execution_count":null,"id":"15329b62-b303-4f06-ade9-473033c30798","metadata":{"execution":{"iopub.execute_input":"2025-10-10T23:48:38.845441Z","iopub.status.busy":"2025-10-10T23:48:38.845229Z","iopub.status.idle":"2025-10-10T23:48:44.781969Z","shell.execute_reply":"2025-10-10T23:48:44.781439Z","shell.execute_reply.started":"2025-10-10T23:48:38.845418Z"},"id":"15329b62-b303-4f06-ade9-473033c30798","executionInfo":{"status":"ok","timestamp":1762132737799,"user_tz":-660,"elapsed":79642,"user":{"displayName":"Paul Butler","userId":"08166718738908281890"}},"colab":{"base_uri":"https://localhost:8080/","height":629,"referenced_widgets":["55114b8f25b4440fa189491310bba37c","36338df9deb24081bee96736b7f41d55","74b54aa5f2e84617b8571b7d6a4fa427","80a5658c03ba40d2aee534edfaf05b6a","03992b89bef644a599c73db6eaff9d85","0f24c14b28f34f6da2682b9ce8829180","7d13a790996e49afbe1cebb930432bad","65d6ac59b37941f8abb90e6a890fb51f","3b25dad8f7db4c7a8fb18dcc6ff4f7f0","f4fad90286ad45328b08e6b3289b6874","3b98730cb15546bb9eef640548482e89"]},"outputId":"1e16b84a-9a4d-4c85-e139-7305b14e0464"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Batches:   0%|          | 0/877 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55114b8f25b4440fa189491310bba37c"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["                                              instruction  \\\n","0       If you are a doctor, please answer the medical...   \n","1       If you are a doctor, please answer the medical...   \n","2       If you are a doctor, please answer the medical...   \n","3       If you are a doctor, please answer the medical...   \n","4       If you are a doctor, please answer the medical...   \n","...                                                   ...   \n","112160  If you are a doctor, please answer the medical...   \n","112161  If you are a doctor, please answer the medical...   \n","112162  If you are a doctor, please answer the medical...   \n","112163  If you are a doctor, please answer the medical...   \n","112164  If you are a doctor, please answer the medical...   \n","\n","                                                    input  \\\n","0       I woke up this morning feeling the whole room ...   \n","1       My baby has been pooing 5-6 times a day for a ...   \n","2       Hello, My husband is taking Oxycodone due to a...   \n","3       lump under left nipple and stomach pain (male)...   \n","4       I have a 5 month old baby who is very congeste...   \n","...                                                   ...   \n","112160  im 25 years old ..i started using mtp kit on 5...   \n","112161  My 5 year old son has been coughing for a mont...   \n","112162  My toes on right foot more than left are numb ...   \n","112163  I was diagnosis with pleurisy last Tuesday, an...   \n","112164  Within the past few hours, my husband has deve...   \n","\n","                                                   output  \\\n","0       Hi, Thank you for posting your query. The most...   \n","1       Hi... Thank you for consulting in Chat Doctor....   \n","2       Hello, and I hope I can help you today.First, ...   \n","3       HI. You have two different problems. The lump ...   \n","4       Thank you for using Chat Doctor. I would sugge...   \n","...                                                   ...   \n","112160  Hello, Thanks for letting us know your health ...   \n","112161  As you have mentioned in your history that you...   \n","112162  Hi. The numbness and blue discoloration could ...   \n","112163  Thanks for your question on Chat Doctor. Treat...   \n","112164  Hello, Thank you for posting on Chat Doctor. T...   \n","\n","                                                 combined  \n","0       I woke up this morning feeling the whole room ...  \n","1       My baby has been pooing 5-6 times a day for a ...  \n","2       Hello, My husband is taking Oxycodone due to a...  \n","3       lump under left nipple and stomach pain (male)...  \n","4       I have a 5 month old baby who is very congeste...  \n","...                                                   ...  \n","112160  im 25 years old ..i started using mtp kit on 5...  \n","112161  My 5 year old son has been coughing for a mont...  \n","112162  My toes on right foot more than left are numb ...  \n","112163  I was diagnosis with pleurisy last Tuesday, an...  \n","112164  Within the past few hours, my husband has deve...  \n","\n","[112165 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-7d0753c0-8cd2-481c-85c2-e9c9fdcad45a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instruction</th>\n","      <th>input</th>\n","      <th>output</th>\n","      <th>combined</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>If you are a doctor, please answer the medical...</td>\n","      <td>I woke up this morning feeling the whole room ...</td>\n","      <td>Hi, Thank you for posting your query. The most...</td>\n","      <td>I woke up this morning feeling the whole room ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>If you are a doctor, please answer the medical...</td>\n","      <td>My baby has been pooing 5-6 times a day for a ...</td>\n","      <td>Hi... Thank you for consulting in Chat Doctor....</td>\n","      <td>My baby has been pooing 5-6 times a day for a ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>If you are a doctor, please answer the medical...</td>\n","      <td>Hello, My husband is taking Oxycodone due to a...</td>\n","      <td>Hello, and I hope I can help you today.First, ...</td>\n","      <td>Hello, My husband is taking Oxycodone due to a...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>If you are a doctor, please answer the medical...</td>\n","      <td>lump under left nipple and stomach pain (male)...</td>\n","      <td>HI. You have two different problems. The lump ...</td>\n","      <td>lump under left nipple and stomach pain (male)...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>If you are a doctor, please answer the medical...</td>\n","      <td>I have a 5 month old baby who is very congeste...</td>\n","      <td>Thank you for using Chat Doctor. I would sugge...</td>\n","      <td>I have a 5 month old baby who is very congeste...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>112160</th>\n","      <td>If you are a doctor, please answer the medical...</td>\n","      <td>im 25 years old ..i started using mtp kit on 5...</td>\n","      <td>Hello, Thanks for letting us know your health ...</td>\n","      <td>im 25 years old ..i started using mtp kit on 5...</td>\n","    </tr>\n","    <tr>\n","      <th>112161</th>\n","      <td>If you are a doctor, please answer the medical...</td>\n","      <td>My 5 year old son has been coughing for a mont...</td>\n","      <td>As you have mentioned in your history that you...</td>\n","      <td>My 5 year old son has been coughing for a mont...</td>\n","    </tr>\n","    <tr>\n","      <th>112162</th>\n","      <td>If you are a doctor, please answer the medical...</td>\n","      <td>My toes on right foot more than left are numb ...</td>\n","      <td>Hi. The numbness and blue discoloration could ...</td>\n","      <td>My toes on right foot more than left are numb ...</td>\n","    </tr>\n","    <tr>\n","      <th>112163</th>\n","      <td>If you are a doctor, please answer the medical...</td>\n","      <td>I was diagnosis with pleurisy last Tuesday, an...</td>\n","      <td>Thanks for your question on Chat Doctor. Treat...</td>\n","      <td>I was diagnosis with pleurisy last Tuesday, an...</td>\n","    </tr>\n","    <tr>\n","      <th>112164</th>\n","      <td>If you are a doctor, please answer the medical...</td>\n","      <td>Within the past few hours, my husband has deve...</td>\n","      <td>Hello, Thank you for posting on Chat Doctor. T...</td>\n","      <td>Within the past few hours, my husband has deve...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>112165 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d0753c0-8cd2-481c-85c2-e9c9fdcad45a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7d0753c0-8cd2-481c-85c2-e9c9fdcad45a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7d0753c0-8cd2-481c-85c2-e9c9fdcad45a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-f1f1e438-6679-4102-8ec9-c24dc3c39294\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f1f1e438-6679-4102-8ec9-c24dc3c39294')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-f1f1e438-6679-4102-8ec9-c24dc3c39294 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_68e5a4d7-0817-4653-acd9-8a358439c371\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_68e5a4d7-0817-4653-acd9-8a358439c371 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('dataset');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"dataset"}},"metadata":{},"execution_count":52}],"source":["# Create a knowledge base by generating embeddings for the combined question-answer pairs from the dataset.\n","dataset = load_dataset('lavita/ChatDoctor-HealthCareMagic-100k', split='train').to_pandas()\n","dataset['combined'] = dataset['input'] + ' ' + dataset['output'] # Combine question and answer for context\n","embeddings = embed_model.encode(dataset['combined'].tolist(), show_progress_bar=True, batch_size=128)\n","dataset"]},{"cell_type":"markdown","id":"99c93554-7b6c-4758-a5d6-55d357bef73b","metadata":{"id":"99c93554-7b6c-4758-a5d6-55d357bef73b"},"source":["# Retrieval and Response Generation\n"]},{"cell_type":"code","execution_count":null,"id":"a7c4dbc3-43af-4706-8437-c5273276b0eb","metadata":{"execution":{"iopub.execute_input":"2025-10-10T23:54:45.845844Z","iopub.status.busy":"2025-10-10T23:54:45.845401Z","iopub.status.idle":"2025-10-10T23:54:45.849882Z","shell.execute_reply":"2025-10-10T23:54:45.849375Z","shell.execute_reply.started":"2025-10-10T23:54:45.845814Z"},"id":"a7c4dbc3-43af-4706-8437-c5273276b0eb"},"outputs":[],"source":["def retrieve_relevant_contexts(query: str, k: int = 3) -> list:\n","    ''' Retrieves the k most relevant contexts to a given query using cosine similarity.\n","\n","    Args:\n","        query (str): The user's medical query.\n","        k (int): The number of relevant contexts to retrieve.\n","\n","    Returns:\n","        list: A list of dictionaries, each containing a relevant context.\n","    '''\n","    query_embedding = embed_model.encode([query])[0] # Generate query embedding\n","    similarities = cosine_similarity([query_embedding], embeddings)[0] # Calculate similarities\n","    top_k_indices = np.argsort(similarities)[-k:][::-1] # Get top k similar contexts\n","    return [{\n","        'question': dataset.iloc[idx]['input'],\n","        'answer': dataset.iloc[idx]['output'],\n","        'similarity': similarities[idx],\n","    } for idx in top_k_indices]"]},{"cell_type":"code","execution_count":null,"id":"2bbb03eb-3258-48de-9ac2-c486c81c15ee","metadata":{"execution":{"iopub.execute_input":"2025-10-10T23:54:45.852235Z","iopub.status.busy":"2025-10-10T23:54:45.852054Z","iopub.status.idle":"2025-10-10T23:54:45.857925Z","shell.execute_reply":"2025-10-10T23:54:45.857418Z","shell.execute_reply.started":"2025-10-10T23:54:45.852218Z"},"id":"2bbb03eb-3258-48de-9ac2-c486c81c15ee"},"outputs":[],"source":["def generate_structured_response(query: str, contexts: list, max_completion_length=1024) -> str:\n","    ''' Generates a detailed response using the retrieved contexts.\n","\n","    Args:\n","        query (str): The user's medical query.\n","        contexts (list): A list of relevant contexts.\n","\n","    Returns:\n","        str: The generated response.\n","    '''\n","    context_prompt = '\\n'.join([ # Prepare prompt with retrieved contexts\n","        f\"Reference {i + 1}:\\nQuestion: {ctx['question']}\\nAnswer: {ctx['answer']}\"\n","        for i, ctx in enumerate(contexts)\n","    ])\n","    prompt = f'''Based on the following references and your medical knowledge, provide a detailed response:\n","\n","References:\n","{context_prompt}\n","\n","Question: {query}\n","\n","By considering:\n","1. The key medical concepts in the question.\n","2. How the reference cases relate to this question.\n","3. What medical principles should be applied.\n","4. Any potential complications or considerations.\n","\n","Give the final response:\n","'''\n","    messages = [{'role': 'user', 'content': prompt}]\n","    inputs = tokenizer(\n","        tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False),\n","        return_tensors='pt',\n","    ).to(model.device)\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            **inputs,\n","            max_new_tokens=max_completion_length,\n","            temperature=0.6,                # Balance creativity and consistency\n","            top_p=0.95,                     # Nucleus sampling for quality\n","            top_k=20,\n","            do_sample=True,                 # Enable sampling for varied reasoning paths\n","            pad_token_id=tokenizer.eos_token_id,\n","            repetition_penalty=1.1,         # Reduce repetitive reasoning steps\n","            length_penalty=1.0,             # Neutral preference for response length\n","            early_stopping=True,            # Stop at natural completion\n","            # streamer=TextStreamer(tokenizer, skip_prompt=True), # Remove streamer for direct output\n","        )\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return response.split('Give the final response:\\n')[-1] # Extract the final response portion"]},{"cell_type":"markdown","id":"b7de9ce4-5c88-4ede-a76e-822e86b25a51","metadata":{"id":"b7de9ce4-5c88-4ede-a76e-822e86b25a51"},"source":["# Putting It All Together"]},{"cell_type":"code","execution_count":null,"id":"fa0a36d3-cd92-4e20-a4fb-8bfc3c8188a1","metadata":{"execution":{"iopub.execute_input":"2025-10-10T23:54:45.860674Z","iopub.status.busy":"2025-10-10T23:54:45.860298Z","iopub.status.idle":"2025-10-11T00:03:19.540263Z","shell.execute_reply":"2025-10-11T00:03:19.539710Z","shell.execute_reply.started":"2025-10-10T23:54:45.860647Z"},"id":"fa0a36d3-cd92-4e20-a4fb-8bfc3c8188a1","executionInfo":{"status":"ok","timestamp":1762132737841,"user_tz":-660,"elapsed":33,"user":{"displayName":"Paul Butler","userId":"08166718738908281890"}},"colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"34de4873-b108-487e-ab71-77b5404f5886"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nquery = \"I\\'m 14 and have really bad acne. A doctor put me on antibiotics for the past 3 weeks but it doesn\\'t seem to help.  What is causing it?\"\\nprint(\\'Query:\\', query, \\'\\n\\n===== Relevant Contexts ===== \\')\\n\\ncontexts = retrieve_relevant_contexts(query)\\nfor i, ctx in enumerate(contexts, 1):\\n    print(f\"Reference {i} (Similarity: {ctx[\\'similarity\\']:.3f}):\")\\n    print(f\"Q: {ctx[\\'question\\']}\")\\n    print(f\"A: {ctx[\\'answer\\']}\\n\")\\n\\nprint(\\'===== Generated Response =====\\')\\nresponse = generate_structured_response(query, contexts)\\nprint(response)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":55}],"source":["# query = \"I've been experiencing persistent headaches and dizziness for the past week. What could be the cause?\"\n","'''\n","query = \"I'm 14 and have really bad acne. A doctor put me on antibiotics for the past 3 weeks but it doesn't seem to help.  What is causing it?\"\n","print('Query:', query, '\\n\\n===== Relevant Contexts ===== ')\n","\n","contexts = retrieve_relevant_contexts(query)\n","for i, ctx in enumerate(contexts, 1):\n","    print(f\"Reference {i} (Similarity: {ctx['similarity']:.3f}):\")\n","    print(f\"Q: {ctx['question']}\")\n","    print(f\"A: {ctx['answer']}\\n\")\n","\n","print('===== Generated Response =====')\n","response = generate_structured_response(query, contexts)\n","print(response)\n","'''"]},{"cell_type":"markdown","source":["# Interface"],"metadata":{"id":"aMxm3-OJ7Jrx"},"id":"aMxm3-OJ7Jrx"},{"cell_type":"code","source":["# Define structured output format for mathematical reasoning\n","REASONING_START = '<THINK>' # Begin reasoning section\n","REASONING_END = '</THINK>'  # End reasoning section\n","ANSWER_START = '<ANSWER>'   # Begin final answer\n","ANSWER_END = '</ANSWER>'    # End final answer\n","\n","# System prompt adapted for RAG + medical reasoning\n","SYSTEM_PROMPT = f'''You are a medical reasoning assistant. When given a medical problem and relevant references:\n","1. Show your step-by-step complex reasoning (including reflection, backtracking, alternative paths, and how references relate) between {REASONING_START} and {REASONING_END}.\n","2. Provide your final answer between {ANSWER_START} and {ANSWER_END}.\n","3. Be precise and show all deliberation steps clearly, considering the following:\n","- Medical aliases/synonyms.\n","- The key medical concepts in the question.\n","- How the reference cases relate to this question.\n","- What medical principles should be applied.\n","- Any potential complications or considerations.'''\n","print(SYSTEM_PROMPT)"],"metadata":{"id":"4-gsE0Y3AGVW","executionInfo":{"status":"ok","timestamp":1762132737845,"user_tz":-660,"elapsed":3,"user":{"displayName":"Paul Butler","userId":"08166718738908281890"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3d4f0945-a3b3-4972-a509-a305841f2557"},"id":"4-gsE0Y3AGVW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["You are a medical reasoning assistant. When given a medical problem and relevant references:\n","1. Show your step-by-step complex reasoning (including reflection, backtracking, alternative paths, and how references relate) between <THINK> and </THINK>.\n","2. Provide your final answer between <ANSWER> and </ANSWER>.\n","3. Be precise and show all deliberation steps clearly, considering the following:\n","- Medical aliases/synonyms.\n","- The key medical concepts in the question.\n","- How the reference cases relate to this question.\n","- What medical principles should be applied.\n","- Any potential complications or considerations.\n"]}]},{"cell_type":"code","source":["class DrChat_Manager:\n","    def __init__(self, mode='stream'):\n","        self.query_history = []\n","        self.mode = mode\n","\n","    def parse_response(self, full_response):\n","        # Parse full response for formatting\n","        think_match = re.search(r'\\s*(.+?)\\s*</THINK>', full_response, re.DOTALL | re.IGNORECASE)\n","        answer_match = re.search(r'<ANSWER>\\s*(.+?)\\s*</ANSWER>', full_response, re.DOTALL | re.IGNORECASE)\n","        think_text = think_match.group(1).strip() if think_match else \"No explicit thinking section generated.\"\n","        answer_text = answer_match.group(1).strip() if answer_match else full_response.strip()\n","        return think_text, answer_text\n","\n","    def chat_manager(self, message, history):\n","        pos_dir = ['y', 'yes', 'yep', 'ok']\n","        neg_dir = ['n', 'no', 'nope']\n","\n","        if message.lower() in pos_dir:\n","            if self.query_history[-1]['role'] == 'assistant':\n","                think_text, _ = self.parse_response(self.query_history[-1]['content'])\n","                yield (think_text)\n","        elif message.lower() in neg_dir:\n","            yield \"Ok, anything else you need help with?\"\n","        else:\n","            # Process query\n","            self.query_history.append({'role': 'user', 'content': message})\n","\n","            conversation = [{'role': 'system', 'content': SYSTEM_PROMPT}]\n","            conversation.append({'role': 'user', 'content': message})\n","\n","            contexts = retrieve_relevant_contexts(message, k=3) # Retrieve contexts based on current message\n","            context_prompt = '\\n'.join([ # Prepare prompt with retrieved contexts\n","                f\"Reference {i + 1}:\\nQuestion: {ctx['question']}\\nAnswer: {ctx['answer']}\\n\"\n","                for i, ctx in enumerate(contexts)\n","            ])\n","\n","            augmented_message = f'''\\n\\nBased on the following references and your medical knowledge, provide a detailed response:\n","\n","                References:\n","                ```\n","                {context_prompt}\n","                ```\n","                Question: {message}\n","                '''\n","\n","            conversation[-1]['content'] = augmented_message\n","            text = tokenizer.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False) # Render into a single string and append <THINK> for generation\n","            inputs = tokenizer(text, return_tensors='pt').to(model.device)\n","\n","            start_time = time.time()\n","            streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n","            generation_kwargs = dict(\n","                inputs,\n","                max_new_tokens=1024,\n","                temperature=0.6,                # Balance creativity and consistency\n","                top_p=0.95,                     # Nucleus sampling for quality\n","                top_k=20,\n","                do_sample=True,                 # Enable sampling for varied reasoning paths\n","                pad_token_id=tokenizer.eos_token_id,\n","                repetition_penalty=1.1,         # Reduce repetitive reasoning steps\n","                length_penalty=1.0,             # Neutral preference for response length\n","                early_stopping=True,            # Stop at natural completion\n","                streamer=streamer,\n","            )\n","\n","            start_time = time.time()\n","            thread = threading.Thread(target=model.generate, kwargs=generation_kwargs)\n","            thread.start()\n","\n","            full_response = \"\"\n","            for new_text in streamer:\n","                full_response += new_text\n","                if self.mode == 'stream':\n","                    yield full_response # Stream partial response in UI\n","\n","            end_time = time.time()\n","            thinking_time = end_time - start_time\n","\n","            self.query_history.append({'role': 'assistant', 'content': full_response})\n","\n","            think_text, answer_text = self.parse_response(full_response)\n","\n","            if self.mode == 'stream':\n","                # Format with collapsible HTML\n","                formatted_response = (\n","                    f'<details><summary>Contexts</summary>'\n","                    f'<p>{context_prompt}</p>'\n","                    f'</details>\\n\\n'\n","                    f'<details><summary>Thinking (took {thinking_time:.2f} seconds)</summary>'\n","                    f'<p>{think_text}</p>'\n","                    f'</details>\\n\\n'\n","                    f'Final diagnosis\\n{answer_text}'\n","                )\n","\n","                yield formatted_response\n","            else:\n","                yield (answer_text + '\\nWould you like the rational for the diagnosis?')\n","\n"],"metadata":{"id":"ttvnJaa_fubH"},"id":"ttvnJaa_fubH","execution_count":null,"outputs":[]},{"cell_type":"code","source":["## DoctorRL chatbot interface\n","\n","drRL = DrChat_Manager(mode='stream')\n","\n","example_qs = ['I have pain in my chest and left arm and I feel dizzy.',\n","              'I have blocked nose, cough, slightly high temperature and am finding it difficult to eat.',\n","              'I have a fever, stiff neck and sore eyes from bright lights.',\n","              'I have a buring pain in the back of my right leg and it feels weak.'\n","              ]\n","\n","chat_ui = gr.ChatInterface(\n","    fn=drRL.chat_manager,\n","    type=\"messages\",\n","    textbox=gr.Textbox(placeholder='What seems to be the problem, please describe your symptoms', container=False, scale=7),\n","    title='Doctor RL',\n","    description='Doctor RL is for academic purposes only and may make errors.  See a qualified medical professional for health advice.',\n","    examples=example_qs,\n","    chatbot=gr.Chatbot(placeholder=\"<strong>Welcome to Doctor RL.  What are your symptoms?\", height=650),\n","    flagging_mode=\"manual\",\n","    flagging_options=[\"Like\", \"Wrong\", \"Inappropriate\"],\n","    save_history=True\n",")\n","\n","chat_ui.launch(share=True, debug=True)\n","\n"],"metadata":{"id":"SHyRCiw-GYDR","executionInfo":{"status":"ok","timestamp":1762134356186,"user_tz":-660,"elapsed":1618334,"user":{"displayName":"Paul Butler","userId":"08166718738908281890"}},"colab":{"base_uri":"https://localhost:8080/","height":715},"outputId":"71da4586-a864-4a4c-82a7-0ad71ab97854"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1355077632.py:18: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n","  chatbot=gr.Chatbot(placeholder=\"<strong>Welcome to Doctor RL.  What are your symptoms?\", height=650),\n","/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:323: UserWarning: The type of the gr.Chatbot does not match the type of the gr.ChatInterface.The type of the gr.ChatInterface, 'messages', will be used.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://73f8f3023ef7d1e79f.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://73f8f3023ef7d1e79f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://73f8f3023ef7d1e79f.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":58}],"id":"SHyRCiw-GYDR"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"},"colab":{"provenance":[{"file_id":"1IL9_gUcEkkvdUmL08opEepKlofLJ65Jh","timestamp":1761786217400}],"gpuType":"A100","machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6b5bf91909d14565a0a86c58c6e8ba0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74cfc90539d44500972378dfe2f45f9d","IPY_MODEL_8f8a4a5d25eb44e6ab752aea0d345f1c","IPY_MODEL_d99bef70a19a4f3596d88477189f42ee"],"layout":"IPY_MODEL_daac6cd95fa44d1da290766aedc9ca0f"}},"74cfc90539d44500972378dfe2f45f9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81ea6fe82804471a8f0480e5b49c0400","placeholder":"​","style":"IPY_MODEL_c1dab6533f3346d4aa13226ab8f4b641","value":""}},"8f8a4a5d25eb44e6ab752aea0d345f1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7020cc112f3f4249987a628f3a6e33e1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d72a6739b314d1e802457b903a9bc47","value":1}},"d99bef70a19a4f3596d88477189f42ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e29aee0fdbd042159df67fb9f470256e","placeholder":"​","style":"IPY_MODEL_fecedfb4578a47f3a6a8a859bff7e1f9","value":"Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00&lt;00:00,  1.02it/s]\n"}},"daac6cd95fa44d1da290766aedc9ca0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81ea6fe82804471a8f0480e5b49c0400":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1dab6533f3346d4aa13226ab8f4b641":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7020cc112f3f4249987a628f3a6e33e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d72a6739b314d1e802457b903a9bc47":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e29aee0fdbd042159df67fb9f470256e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fecedfb4578a47f3a6a8a859bff7e1f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55114b8f25b4440fa189491310bba37c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36338df9deb24081bee96736b7f41d55","IPY_MODEL_74b54aa5f2e84617b8571b7d6a4fa427","IPY_MODEL_80a5658c03ba40d2aee534edfaf05b6a"],"layout":"IPY_MODEL_03992b89bef644a599c73db6eaff9d85"}},"36338df9deb24081bee96736b7f41d55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f24c14b28f34f6da2682b9ce8829180","placeholder":"​","style":"IPY_MODEL_7d13a790996e49afbe1cebb930432bad","value":"Batches: 100%"}},"74b54aa5f2e84617b8571b7d6a4fa427":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65d6ac59b37941f8abb90e6a890fb51f","max":877,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b25dad8f7db4c7a8fb18dcc6ff4f7f0","value":877}},"80a5658c03ba40d2aee534edfaf05b6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4fad90286ad45328b08e6b3289b6874","placeholder":"​","style":"IPY_MODEL_3b98730cb15546bb9eef640548482e89","value":" 877/877 [01:12&lt;00:00, 22.19it/s]"}},"03992b89bef644a599c73db6eaff9d85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f24c14b28f34f6da2682b9ce8829180":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d13a790996e49afbe1cebb930432bad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65d6ac59b37941f8abb90e6a890fb51f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b25dad8f7db4c7a8fb18dcc6ff4f7f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4fad90286ad45328b08e6b3289b6874":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b98730cb15546bb9eef640548482e89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}